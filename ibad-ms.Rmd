---
title             : "Big data about small people: The Play & Learning Across a Year (PLAY) Project"
shorttitle        : "PLAY Project"

author: 
  - name          : "Rick O. Gilmore"
    affiliation   : "1,3"
    corresponding : yes    # Define only one corresponding author
    address       : "Department of Psychology, University Park, PA 16802"
    email         : "rogilmore@psu.edu"
  - name          : "Karen E. Adolph"
    affiliation   : "2,3"
  - name          : "Catherine L. Tamis-LeMonda"
    affiliation   : "2"
  - name          : "Kasey Soska"
    affiliation   : "3"
  - name          : "Joy L. Kennedy"
    affiliation   : "2,3"

affiliation:
  - id            : "1"
    institution   : "The Pennsylvania State University"
  - id            : "2"
    institution   : "New York University"
  - id            : "3"
    institution   : "Databrary.org"

author_note: |
  Rick O. Gilmore is in the Department of Psychology, The Pennsylvania State University, University Park, PA 16802.
  Karen E. Adolph is in the Department of Psychology, New York University, 4 Washington Place, New York, NY 10003.
  Catherine L. Tamis-LeMonda is in the Department of Applied Psychology, New York University.
  Kasey Soska is is Scientific Project Director at Databrary.
  Joy L. Kennedy is Scientific Support Specialist at Databrary.
  We acknowledge support from the National Science Foundation (BCS-1238595), the Eunice Kennedy Shriver National Institute for Child Health and Human Development (U01-HD-076595), the Society for Research in Child Development, the Alfred P. Sloan Foundation, and the LEGO Foundation.

abstract: |
  Piaget, Montessori, and Bruner observed that play is the work of infants.
  The PLAY (Play & Learning Across a Year) project seeks to catalyze discovery about the form and dynamics of this essential work across a critical period from 12 to 24 months of age when infants show remarkable advances in language, object interaction, locomotion, and emotion regulation.
  PLAY will leverage the joint expertise of 65 “launch group” researchers and capitalize on the Databrary video-sharing library and Datavyu video-coding tool to exploit the power of video to reveal the richness and complexity of behavior. 
  The PLAY researchers will collect, transcribe, code, share, and exploit a video corpus of infant and mother naturalistic activity in the home to test hypotheses about behavioral, developmental, and environmental cascades. 
  In turn, the project will demonstrate the value and feasibility of a cross-domain synergistic approach to infant research while advancing new ways to use video as data and documentation to facilitate discovery and ensure transparency.
  
keywords          : "keywords"
wordcount         : "X"

bibliography      : ["bib/r-references.bib", "bib/play.bib"]

figsintext        : no
figurelist        : no
tablelist         : no
footnotelist      : no
lineno            : yes

lang              : "english"
class             : "man"
output            : 
  papaja::apa6_pdf: default
  html_document:
    toc_float: true
    toc: true
  github_document:
    toc: true
  word_document: default
params:
  databrary.account: default
---

```{r configure-document, include = FALSE}
knitr::opts_chunk$set(echo = FALSE, 
                      warning = FALSE, 
                      error = FALSE,
                      message = FALSE,
                      dpi = 72,
                      cache = TRUE,
                      autodep = TRUE
                      )
```

```{r load_packages, include = FALSE}
library(papaja)
library(tidyverse)
library(httr)
library(stringr)
library(choroplethr)
library(choroplethrMaps)
library(tidyr)
library(databraryapi)
library(ggmap)
library(chron)

if (params$databrary.account == "default") {
  stop("Must specify Databrary account as parameter in file header or in call to rmarkdown::render().")
}
if (!login_db(params$databrary.account)) {
  stop("Error logging in to Databrary. Try config_passwd().")
}

PLAY.nichd.vol.id <- 254
PLAY.nichd.session.id <- 26338
PLAY.pis.asset.id <- 117090

play.palette <- scale_fill_manual(values=c("blue2", "firebrick2", "chartreuse2", "darkorchid2"))

play.theme <-   
  theme_classic() +
  theme(legend.position = "bottom",
        legend.title = element_blank(),
        legend.text = element_text(size = rel(1.2)),
        axis.title = element_text(size = rel(1.5), 
                                  face ="bold"),
        axis.text.x = element_text(size = rel(1.2)),
        axis.text.y = element_text(size = rel(.7)),
        axis.line = element_blank(),
        axis.title.y = element_blank())
```

```{r get-install-census-key, include = FALSE}
# Get a Census API key from <https://api.census.gov/data/key_signup.html>
# install it via acs::api.key.install(key)
```

```{r analysis_preferences, include = FALSE}
# Seed for random number generation
set.seed(42)

csv.dir <- "csv/"
r.dir <- "csv/"

source("R/numbers2words.R")
source("R/Cap_all.R")
source("R/Init_cap.R")
source("R/census.api.key.R")


```

Behavior lies at the core of developmental science [@Gibson1994-kb].
Video is a uniquely powerful tool for capturing the richness and complexity of behavior [@Adolph2017-ac; @Gilmore2017-eh], documenting its microstructure in real time and global patterns of change over development [@Gesell1991-sx; @Gesell1946-qr]. 
Video chronicles who did what, and how, when, and where they did it [@Gilmore2016-wl; @Gilmore_undated-tp; @Adolph2017-ac].
Most infancy researchers collect video as primary data or as a backup to online coding procedures, but until recently, few have openly shared video because of ethical and technical challenges.
As those challenges recede and the culture of developmental science begins to embrace more open, transparent, and reproducible practices [@Frank2017-tb], the time is ripe to capitalize on the unique power of video to catalyze discovery and transform knowledge about behavioral development in infancy.

The Play & Learning Across a Year (PLAY) project [@PLAY-workshop-Databrary; @PLAY-pilot-volume] builds on the NICHD/NSF-funded Databrary video-sharing library [@Gilmore2016-ev; @databrary-site] and the Datavyu  video-coding tool [@datavyu-site; @Adolph2015-oy]  developed and supported by Adolph and Gilmore, and it unites the joint expertise of 65 PLAY “launch group” researchers in the United States and Canada. 
PLAY will create the first-of-its-kind, large-scale, openly shared, readily reusable, transcribed, coded, and curated video corpus of human behavior. 
In addition, PLAY seeks to advance new video-based means of research documentation that hold promise to increase transparency and bolster reproducibility [@Adolph2017-ac; @Gilmore2017-eh] across the behavioral sciences.
In this paper, we describe the process of planning PLAY, our preliminary results from a small pilot study, and plans for a larger scale implementation we expect to launch in late 2018.

# Project Planning

```{r get-PLAY-roster}
#play.pis <- read_csv("csv/play-pis.csv")
play.pis <- read_csv_data_as_df(PLAY.nichd.session.id, PLAY.pis.asset.id)
if (is.null(play.pis)) {
  stop("Error downloading PLAY PI data from Databrary.")
}
n.pis <- length(unique(paste0(play.pis$Last, play.pis$First)))
n.institutions <- length(unique(play.pis$Institution))
n.states <- length(unique(play.pis$State))
```
## Why's and wherefore's

We named the project “PLAY” and use the terms “unstructured play” and “everyday play” to broadly refer to infants’ natural activities while awake. 
To paraphrase Piaget [@Piaget1967-nl], Montessori [@Montessori1984-la], and Bruner [@Bruner1975-sp; @Bruner1976-ab], play is the work of infants.
It is an approach to action, not a particular form of activity.
Some of infants’ play involves toys and some play is joyful and goal directed, but all of their spontaneous vocalizations, interactions with objects and people, and locomotor bouts involve exploration and opportunities for learning and growth, regardless of affect or intent.

## Recruiting the launch group
Planning for the project began in late 2015.
Adolph, Tamis-LeMonda and Gilmore (PLAY PIs) invited researchers to join the launch group based on their interest in open science and infant-mother natural activity in the home, willingness to collaborate on data collection and coding, lab location, and domains of expertise (language, gesture, play, object exploration, tool use, locomotion, posture, physical activity, emotion, temperament, parent responsiveness, gender, home environment, media use, spatial demography, and sampling). 
Nearly every invitee agreed.
As of Spring 2018, the current launch group consists of `r n.pis` researchers from `r n.institutions` institutions and `r n.states` states. `r round(with(play.pis, table(New)/sum(table(New)))*100, 0)[1]`% are new investigators, `r round(with(play.pis, table(Gender)/sum(table(Gender)))*100, 0)[1]`% women, `r round(with(play.pis, table(Race_eth)/sum(table(Race_eth)))*100, 0)[1]` non-white, from varied institutions (public and private universities and colleges, hospitals, agencies) with varied resources (`r sum(round(with(play.pis, table(Institution_Type)/sum(table(Institution_Type)))*100, 0)[1:3])` public universities, `r round(with(play.pis, table(R15_eligible)/sum(table(R15_eligible)))*100, 0)[1]`% R15-eligible institutions) across the United States and Canada.

To distribute the burden of video coding across researchers, we recruited more than 10 experts to shape the development of coding passes in four fundamental domains--communication, object interaction, locomotion, and emotion.
These domains represent key areas of infant development and provide foundational information for future discovery when time-locked to video.

## Launch group deliberations and decisions

Through a yearlong series of telephone conversations with each launch group member and 12 group webinars [@PLAY-webinar-Databrary], we jointly developed a common sampling method and protocol (including materials, technical specifications, questionnaires, and non-video measures), designed common video codes, and established an infrastructure to divide responsibilities between PLAY staff and launch group.
We achieved consensus, with input from NICHD program staff, about all aspects of PLAY at a daylong workshop at NIH in December 2016, materials from which are shared on Databrary [@PLAY-workshop-Databrary].

The launch group jointly decided that the centerpiece of PLAY would be 900 one-hour videos of infant-mother dyads during natural play in the home. 
Home videos are widely believed to be representative of natural activity, and provide a stark contrast to the 2- to 20-minute "snapshots" typical of standard structured lab tasks.
Based on their extensive experience with naturalistic home observations [@Karasik2011-mf; @Karasik2014-cd; @De_Barbaro2015-bp; @Karasik2012-jq; @Karasik2015-mi; @Soderstrom2013-xn; @Rowe2012-vy; @Fausey2016-kx; @Iverson2007-yr], launch group members determined that one hour is sufficiently long to capture an ecologically valid window into infant and mother natural behaviors.
Longer recording times produce diminishing returns, risk infants becoming excessively tired or hungry, and increase the cost and burden to families and researchers.

The launch group determined the specific foundational codes to be applied to the videos in each of the domains of language and communication, locomotion and physical activity, object interaction, and emotional expression.
The foundational codes were chosen to be informative even to non-experts and were designed to facilitate further discovery through subsequent coding passes that build on the prior work.
The codes were intendd to be quick, easy, and reliable to code in comparison with some other behaviors (e.g., visual attention) *not* chosen for coding.
Temporally aligned transcriptions and codes should enable researchers with expertise in any domain to analyze cascades within and among these behaviors.
Experts in language and communication also recommended that we transcribe all mother speech and infant vocalizations in formats exportable to CHILDES [@MacWhinney2000-yn]. 

Given the cost of going to families’ homes, the launch group determined that we should augment recordings of natural play with a set of additional video, questionnaire, and non-video measures, that together would add only ~45 minutes to the home visit. 
This would enable researchers to test whether variations in natural play, or in characteristics of distal and proximal environments, predict infant and mother behaviors when materials and conditions are held constant. 
Thus, the solitary and dyadic play tasks are of interest in their own right, and might also serve as correlates in tests of experiential and environmental influences.

To obtain objective data on stable home conditions (cracks in walls, broken windows, ceiling stains, safety issues, etc.), physical layout (furniture, clutter, space to move, etc.), educational and electronic media (writing/drawing materials, TVs, computers, etc.), and gendered characteristics of infants’ room, toys, and clothes, we decided to conduct video home tours.
Launch group experts also expressed interest in understanding whether clothing and footgear affect infants’ locomotion and physical activity, and each takes only moments to video record.
Clothing/footgear videos can reveal gendered features (bows/frills, superhero emblems, patent leather shoes, army boots) [@Halim2013-ez] and influences on spontaneous activity and locomotion [@Cole2012-vr].
The launch group also deemed important a variety of questionnaire measures of infant skills, experiences, and home environment: mothers’ report of infants’ vocabulary, locomotor milestones and falls, temperament, and use of gender labels; mother’s report of family demographics, media use, health, and home chaos; and a researcher-completed survey on physical characteristics of the home. 
The PIs developed a custom tablet-based app to collect these questionnaire data efficiently, limit data input errors, use a stylus for flexible data entry, and allow automatic transfer to permanent storage on Databrary.
The launch group devised methods to measure room size with a commercial laser device and ambient noise level with a commercial decibel meter.

# Pilot Study

Based on the launch group's initial recommendations, we carried out a pilot study in the New York City area to test the feasibility of the approach.
We chose to recruit infants at 12-, 18-, and 24-months because 12- to 24-months represents a period of important, rapid growth when children begin talking, using objects in symbolic play, walking, and regulating emotions. 
For example, by 12 months, about half of infants can walk and half still crawl. 
By 18 months, infants are proficient walkers, and by 24 months, they can run, walk backwards, and walk up stairs [@Robinson2015-qe; @Onis2006-le]. 
Around 12 months, infants produce their first words. 
By 18 months, most display a vocabulary spurt, and by 24 months infants combine words into simple sentences [@Bloom1995-xb; @Hoff2013-er]. 
But these ages represent only group averages; individual infants show tremendous variability in these behaviors at each age.

## Methods

### Participants

```{r calculate-demo-data}
#vol.444 <- read_csv(paste0(csv.dir, "play-pilot-demographics.csv"))
vol.444 <- download_session_csv(volume = 444)
# Drop materials session(s)
vol.444 <- vol.444 %>% 
  filter(., !is.na(participant.ID), 
         !(participant.gender == ""),
         !(participant.race == ""),
         !(participant.ethnicity == ""),
         !(group.name == ""))
n.subs <- dim(vol.444)[1]

age.by.gender <- xtabs(formula = ~ participant.gender + group.name, data = vol.444)

race.by.ethnicity <- xtabs(formula = ~ participant.race + participant.ethnicity, data = vol.444)

n.white <- sum(race.by.ethnicity['White',])
n.asian <- sum(race.by.ethnicity['Asian',])
n.multi <- sum(race.by.ethnicity['More than one',])
n.unreported <- sum(race.by.ethnicity['Unknown or not reported',])
n.hispanic <- sum(race.by.ethnicity[,'Hispanic or Latino'])
```

A total of $n=$ `r n.subs` infants were tested, $n=$ `r sum(age.by.gender[,'12 mos'])` 12-month-olds (`r age.by.gender['Female','12 mos']` female), $n=$ `r sum(age.by.gender[,'18 mos'])` 18-month-olds (`r age.by.gender['Female','18 mos']` female), and $n=$ `r sum(age.by.gender[,'24 mos'])` (`r age.by.gender['Female','24 mos']` female) 24-month-olds. 

All infants recruited were from the New York City area. 
`r Init_cap(numbers2words(n.white))` infants were White, `r numbers2words(n.asian)` was Asian, `r numbers2words(n.multi)` reported more than one race, and `r numbers2words(n.unreported)` did not report a race.
`r Init_cap(numbers2words(n.hispanic))` were of Hispanic or Latino ethnicity.

### Procedure

During an initial screening call, a researcher determined eligibility for participation and obtained demographic information. 
The researcher scheduled a 2-hour visit (weekday or weekend) when infants were to be between naps, meals, and baths, and would normally be home with their mothers. 

The visit included parent consent, one-hour natural play, two structured play tasks, questionnaires, video home tour, and Databrary sharing permission. 
Although mothers were asked to agree to share data in the initial screening call, we requested their signed permission at the end of the home visit when they were maximally informed about the procedures that had taken place. 
If families decline to share, their data were still be stored on Databrary as "Private" and thus available for use only by the collecting researchers for their own purposes.
Consent, sharing permission, and questionnaire data were entered on a custom Android tablet app; paper forms and video camera on tripod provided backup. 

During the visit, we recorded one hour of infant and mother activity in the home.
Infant and mother went about their daily routines without restrictions.
They could move from room to room; mother could do chores; TV, music, or other media could be on.
The researcher held an HD video camera at the child’s eye level, prioritizing view of infant over mother, keeping the infant’s face, hands, and feet in view. 
If mother was visible, the researcher captured as much of her face and body as possible without losing view of the baby. 
A cardioid microphone amplified infant and mother speech and isolated background noise.

Two structured play tasks followed the one hour of natural activity.
Solitary play entailed infants playing with a set of 10 nesting cups (placed half up, half down) while sitting on a mat with mother nearby but not interacting (2 minutes). 
In dyadic play infant and mother played together on the mat with a standard set of toys (3 minutes)-- truck, doll, baby bottle, small blanket, 2 tea cups, plates, and spoons—with mother instructed to “share the toys with her child.” 
The toys were thought to be conducive to non-symbolic (stacking plates, cups), symbolic (feeding doll, putting doll to sleep), and gendered play (with truck versus doll).

Following the play episodes, the researcher walked through each room, recording walls, floors, ceilings, windows, room contents (including infants’ toys, books, media), and the contents of infants’ closets and drawers. 
The mother was asked to name each room, describe infant’s access to rooms and spaces, and open closet doors and drawers for recording. 
Prior work gave us confidence that mothers would not find this procedure intrusive. 
The researcher narrated the video with comments about floor coverings (“throw rug,” “linoleum”) and anything not transparent to video.

In addition, during the visit the researcher recorded the clothes (front and back) and footgear (bottom, side, top) infants wore during the natural play session, and recorded the date infants began wearing the shoes and for how many days/week infants play indoors in shoes, socks, and barefoot.

After the naturalistic and structured play tasks, the researcher interviewed mothers on a range of infant and family measures that will yield information about language, locomotion, temperament, gender, home environment, and health. The researcher administered all questionnaires orally, and video records the interview (camera on tripod) for quality assurance, transparency, and possibly later coding.

At the end of the visit, the researcher asked mothers if the one-hour natural play session was representative of a typical day at home. 
If mothers reported that infants’ behavior or health was atypical, we would have replaced the dyad and documented the replacement.

A publicly-accessible wiki [@Soska2016-yo] was used to document all procedures and code definitions.
The wiki links descriptions of every aspect of the protocol with exemplar third-person video clips (e.g., researcher scheduling home visit) to demonstrate typical procedures. 
The wiki links text-based descriptions of each code to video clips illustrating the types of behaviors that do and do not satisfy the coding criteria.

### Data analysis

For this report, we used `r cite_r("r-references.bib")` for all of our statistical analyses.
Datavyu [@datavyu-site] was used for video coding.
All code used in data analysis and for this manuscript may be found in the GitHub repository associated with the paper [@ibad-PLAY-github].

To compute inter-observer reliability, we ran scripts in Datavyu to selects a random segment of video (25% or 5 mins) from each 20- minute segment of natural play. 
Inter-observer reliability for the pilot videos was 96.7%-99.3% exact frame agreement ($\kappa$s > .93, $ps$ < .001) for duration codes (object interactions, locomotion, emotion) and 94.1%- 99.5% code agreement ($\kappa$s > .89, $ps$ < .001) for categorical events (communicative acts, gesture).

## Results

Our pilot tests verified the feasibility of collecting all data in less than 2 hours.
So, with 1-2 hours of round-trip travel time, the entire data collection could be completed in less than 4 hours.

Informal inspection of the videos verified that dyads were unaffected by the presence of the researcher: After a few minutes of acclimation prior to natural play, mothers and infants ignore the researcher.
Infants cried and breastfed; mothers yelled, talked on the phone, worked on computers, went about daily chores, changed infants’ diapers, and gave infants snacks.
Mothers appeared comfortable with all procedures, including the video home tour.
The PIs found wide variation in home "disarray," suggesting parents present homes as they would for any other casual visitor.

All families were asked permission to share data with authorized researchers on Databrary using language adapted from the Databrary release template [@databrary-release].
Nineteen of the 20 families agreed to share; 3 families agreed to share data only with authorized Databrary researchers and 16 agreed to allow authorized researchers to show clips in public settings for informational or educational purposes.

In carrying out detailed video coding on 4 of the participants' sessions, we established that all four foundational coding passes are easy to learn (by undergraduate coders on Datavyu) and time efficient (< 3 hours for both infant and mother for each coding pass per hour of video).
Adaptations to Datavyu enable transcription in English or Spanish to take 7-9 hours per hour of video, while infant and mother communicative acts and gestures together take < 3 hours to code.

### Demographic and self-report measures

Due to some technical difficulties with pilot versions of the tablet app, we are only able to report here demographic and self-report data from $n=$ 18 families.
Reconstructions of the missing data from video are ongoing, and updates will appear on the project's Databrary volume [@play-pilot-volume] once those are completed.

```{r locomotion-plot, fig.cap = "Parent-reported onset ages for hands and knees crawling and walking"}
locomotion <- read_csv_data_as_df(26295, 117092)
#locomotion <- read.csv(paste0(csv.dir, "locomotion.csv"))

locomotion %>%
  gather(key = milestone, value = age.mos, hkcrawl_onset_mos, walk_onset_mos) %>%
  mutate(milestone = factor(milestone, labels = c("crawl", "walk"))) %>%
  # arrange(desc(age.mos)) %>%
  ggplot() +
  aes(x = age.mos, y = as.factor(id)) +
  geom_line(aes(group = id)) +
  geom_point(aes(shape = milestone, color = milestone)) +
  xlab("Age (months)") +
  ylab("Participant ID") +
  geom_rug(aes(x = age.mos, group = milestone, color = milestone),
           sides = "b") +
  theme(axis.line.y = element_blank()) +
  play.theme
```

```{r childbirth-data}
cb <- read_csv_data_as_df(26295, 116791)[,1:10]
cb$bw_g <- 453.592*(cb$birth_weight_pounds + cb$birth_weight_ounces/16)
bw.sum <- summary(cb$bw_g)
```

Infants had largely uncomplicated, healthy births. 
Birth weights (in g) ranged from `r min(bw.sum)` to `r max(bw.sum)` (mean = `r mean(bw.sum)` g); `r length(with(cb, table(newborn_complications)))` had birth complications (e.g., C-section, preeclampsia).
Figure \@ref{fig:locomotion-plot} shows the parent-reported ages for the onset of hands and knees crawling and walking using procedures Adolph has used previously [@Adolph2003-rw; @Adolph2012-ab].

```{r summarize-family}
#fam <- read_csv("csv/family.csv")
fam <- read_csv_data_as_df(26295, 116790)
mom.ed.yrs <- with(fam, table(mom_education))
partner.ed.yrs <- with(fam, table(partner_education))
cohab.w.partner <- with(fam, table(partner_cohabitate))
mom.working <- with(fam, table(mom_working))
partner.working <- with(fam, table(partner_working))
```

Mothers reported having between `r min(fam$mom_education, na.rm = TRUE)` and `r max(fam$mom_education, na.rm = TRUE)` years of education, ($M=$ `r round(mean(fam$mom_education, na.rm = TRUE),1)`) and `r sum(mom.working[c('ft', 'pt')])` were working at least part time.
Sixteen of the eighteen repondents reported a partner cohabitating with the family.
The partner's education level ranged from `r min(fam$partner_education, na.rm = TRUE)` and `r max(fam$partner_education, na.rm = TRUE)` years of education, ($M=$ `r round(mean(fam$partner_education, na.rm = TRUE), 1)`) and `r sum(partner.working['ft'])` were working at least part time.

```{r summarize-language-exposure}
#lang.exp <- read.csv("csv/language-exposure.csv")
lang.exp <- read_csv_data_as_df(26295, 116787)
span.to.child <- with(lang.exp, table(language, exposure_context))['Spanish', 'to_child']
span.in.childcare <- with(lang.exp, table(language, exposure_context))['Spanish', 'childcare']
non.english <- with(lang.exp, (table(id, language)))[,c('Armenian', 'Other', 'French', 'Hindi', 'Spanish', 'Polish', 'Russian')]
```

All of the infants were exposed to and spoken to in English in the home.
Many were spoken to or had exposure to languages other than English.
At home `r span.to.child` infants were spoken to in Spanish; `r span.in.childcare` infants were exposed to Spanish in a childcare setting.
Other children were exposed to Armenian, French, Hindi, Polish, and Russian in the childcare setting.
Six children in this sample were exposed only to English.

### Video coding

NEED figures here.

## Discussion

The pilot study verified that the protocol met the launch group's criteria on scientific and practical grounds.
Four of the full sessions (cases 13, 18, 29, and 20) met all internal criterion benchmarks.
These were used to populate the wiki [@Soska2016-yo] with illustrative exemplars of procedures and code definitions. 

# Planned study

The proposed full study builds upon and extends the pilot [@PLAY-workshop-Databrary; @PLAY-pilot-volume] study.
We described the details in a grant proposal to NICHD submitted in June 2017 that was reviewed in October 2017.
The proposal received a 1st percentile in peer review, and as of April 2018, we are awaiting a formal Notice of Award.

## Methods

### Participants

```{r update-collecting-counties}
play.pis %>%
  filter(Collection_role == "Collecting") ->
  collecting.pis

n.states.collecting <- length(unique(collecting.pis$State))
```

```{r play-site-map, fig.cap="Map of planned data collection sites for PLAY project."}
knitr::include_graphics("figs/PLAY-collection-map-1.pdf")
```

We will collect data from $n=900$ infant-mother dyads from 30 different communities in `r n.states.collecting` states located around the U.S.
Each site will collect data from 30 infants, 10 each at 12-, 18-, and 24-months of age (+/- 1 week), with equal numbers of females and males. 
Figure \@ref{fig:play-site-map} shows a map of the proposed data collection sites.

While not designed to be nationally representative, the data collection sites are diverse in aggregate based on Census data.
To gather Census data reproducibly, we used the `choroplethr` package [@R-choroplethr; @R-choroplethrMaps] to download data from the Census Bureau's public API.
This workflow allows us to easily gather and analyze other Census Bureau data about the communities targeted for sampling.

```{r, race-by-county, fig.cap="Racial composition of counties targeted for PLAY project recruitment."}
knitr::include_graphics("figs/race-by-county-all-regions-plot-1.pdf")
```

```{r PLAY-econ-plot, fig.cap="Median per capita income per year in counties targeted for PLAY project recruitment."}
knitr::include_graphics("figs/per-capita-income-plot-1.pdf")
```

```{r PLAY-ed-plot, fig.cap = "Educational attainment in counties targeted for PLAY project recruitment."}
knitr::include_graphics("figs/ed-attain-bars-plot-1.pdf")
```

```{r PLAY-spanish, fig.cap="Proportion of English-only, Spanish, and Other language speakers in counties targeted for PLAY project recruitment."}
knitr::include_graphics("figs/spanish-speaking-plot-1.pdf")
```

Figure \@ref(fig:race-by-county) shows the proportion of African American, Hispanic/Latino, and Asian residents in the counties surrounding the collection sites from which participating researchers will recruit.
Figures \@ref(fig:PLAY-econ-plot) and \@ref(fig:PLAY-ed-plot) show economic and educational attainment indicators, respectively.
Figure \@ref(fig:PLAY-spanish) shows the proportion of households speaking English-only versus those where Spanish or other languages are spoken, exclusively or in addition to English.
Data collection sites will have soft, advisory recruiting targets based on these sorts of measures for their individual communities.

Families will be two-parent, English and/or Spanish speaking households with resident fathers, with both parents greater than 18 years of age.
Infants will be term firstborns, without birth complications or disabilities, and 12, 18, or 24 months of age (±1 week); half of infants at each age and site will be boys. 

The launch group deliberated over several sampling strategies [@Bornstein2013-mr; @Jager2017-wv; @DavisKean2017-sr].
Ultimately, we decided on homogeneous sampling to contain costs and understand behavioral variation. 
Homogenous sampling maintains some control over sample characteristics through a set of inclusionary criteria (here, firstborn status, English/Spanish home language, term pregnancy, etc.), while maximizing select aspects of diversity (e.g., geography, SES) and retaining sufficient power for group comparisons. 
We ruled against conventional convenience sampling, which leaves sampling decisions entirely to researchers’ discretion. 
Although convenience sampling is easy and cost efficient, it risks yielding a sample that varies on too many demographic dimensions to control. 
At the other extreme, population-based (probability) sampling is cost-prohibitive due to the required sample size. 
The sheer volume of data would prohibit transcription and video coding, and would require hiring and training special researchers for data collection, rather than relying on the existing expertise of the launch group.

### Procedure

A publicly-accessible wiki similar to the one used in the pilot [@Soska2016-yo] will be used to document all procedures and code definitions.

Based on our experiences with the pilot, we will take several precautions to minimize effects of experimenter and camera presence on dyads [@McCune-Nicolich1984-tn; @Stevenson1986-zh]. 
We will train researchers to remain unobtrusive. 
They will stay at a distance, resist talking to mother or infant, and watch the infant through the viewfinder to avoid eye contact. 
Recording will begin after several minutes of infant-mother acclimation to the camera and researcher.

We plan to collect parent-report measures across multiple domains. For the \emph{Language} domain, we will use the 12-month (words and gestures) and 18- to 24-month (words and sentences) versions of the MacArthur-Bates Communicative Development Inventory (MCDI). 
The MCDI is the most widely used instrument of infant language development, administered to over 60,000 children in 23 languages [@Frank2017-bt]. 
The 12-month MCDI measures receptive and expressive vocabulary size and communicative gestures; the 18- to 24-month version contains a larger set of vocabulary items and simple sentence constructions.

\emph{Locomotion}: Mothers will report the onset ages of hands-knees crawling and walking, using cell phone videos, photos, and diaries to jog their memories [@Adolph2003-rw; @Adolph2012-ab]. 
QM2: Mothers will report on infants’ fall-related injuries.
Infant temperament (QE1) will be indexed with the Rothbart Early Childhood Behavior Questionnaire (ECBQ), very short form78,79, which measures dimensions of surgency, negative affect, and effortful control.
Gender (QG1): Mothers will report infants’ use of gender labels (e.g., boy, girl) to refer to themselves or other people. QG2: Mothers will report their own and the father’s attitudes to gender normative behavior (e.g., “I would be upset if my son wanted to dress like a girl”); and household division of labor (e.g., who does cooking).
Environment (NH1): Ambient noise will be measured during natural play with a decibel meter, placed in the main room, to record peak and average dB every 100 ms. NH2: In the home video tour, the researcher will measure room dimensions with a laser distance measurer. QH3: At the end of the visit, the researcher will fill out a survey on the home environment (from launch group member Evans). QH4: Mothers will report use of electronic media (TV, computers, apps, etc.) by infant and family members (from launch group member Barr).
Health (QF1-4): Mothers will report infant, parent, and family demographics, infants’ health history (based on a subset of questions from the ECLS-B 9-month and 2-year interviews), childcare experience, and parents’ and family health history including SLI, ASD, and mental illnesses.

### Video coding

Transcriptions and four core coding passes will be scored for both infant and mother.
PLAY staff will transcribe speech at the utterance level, using standard criteria for segmenting speech [@MacWhinney2000-fb]. 
Utterances will be defined by independent clauses (statements with subject and predicate) with modifiers. Intonation and pauses can also define breaks (e.g., “You like that . Right?” is two utterances). 
Mothers’ language-like sounds are typed out phonetically. 
Infant babbles are marked with “b” and non-linguistic vocalizations (cry, laugh, grunt) with “c.” 
Unintelligible utterances are marked “xxx.” Utterances will be time-locked to video, revealing overlaps in infant-mother speech, and co-occurrence and sequencing of speech with object interactions, emotions, and locomotion. Spanish transcriptions will follow the same rules.

Based on transcripts, mothers' utterances will be coded as declaratives (labels and descriptions of objects and events “Red”; “Puppy”), attention-imperatives that solicit infant attention (“Look at that”), action-imperatives that solicit infant action (“Put it there”), or prohibition-imperatives (“Stop it!”); interrogatives (open- and close-ended questions, “Is it hot?” with the exception of “tag” questions, which will be coded as declaratives, “That’s a ball, right?”); affirmation/conversational fillers (“Yes!”; “What’s next?”), and unintelligible. Infants’ vocalizations will be categorized as language (sentences or words), prelinguistic vocalizations (babbling or vowels), non-linguistic vocalizations (e.g., cry, laugh, scream, grunt), or unintelligible.

Gestures will be categorized as points, show/hold up (deictic), conventional (wave bye-bye, thumbs-up), and representational (flapping arms to represent a bird).

Object interactions will be coded for onset and offset of manual engagement (touching, manipulating, carrying) with any manipulable, moveable object or part of an object that moves through space.
Locomotion will be coded for onset and offset of self-generated locomotion of any form (e.g., crawling, walking, climbing, stepping in place). Coders also score falls, and periods when the infant is held or constrained by furniture (e.g., highchair).
Emotion will be coded for onset and offset of positive (smiling, laughing) and negative (crying, frowning, fussing) facial expressions.
Inter-observer reliability: 

To verify inter-observer reliability, PLAY staff will rescore 25% of each infant’s natural play video (5 minutes randomly drawn from each 20-minute segment), blind to the original coders’ output (categorical measures: kappas >.85; duration measures: % exact frame agreement > 90%). If codes are not reliable, PLAY staff will reassign the videos to a new lab.

### Data analysis

The launch group will jointly establish best practices for PLAY analyses.
Our guidelines will include: recommendations to pre-register predictions and analyses; the use of procedures that use one portion of the data set to explore correlations among variables and a separate subsample to confirm it; the use of reproducible and transparent workflows for data processing and analyses (e.g., Ruby scripts in Datavyu; syntax instead of menu-driven commands for SPSS users; scripts and functions for R users); a commitment to openly sharing supplementary video codes and operational definitions to avoid unnecessary duplication of coding efforts; and open sharing of null results as well as positive findings. 
We will create means for communication (e.g., a Google group) among launch group members who wish to discuss, propose, and organize team efforts focused on answering specific video-based research questions.
In addition, in keeping with emerging standards in research transparency [@Simmons2012-ma], we will report how we determined our sample size, all data exclusions (if any), all manipulations, and all measures in the study. 

# General Discussion

The PLAY corpus will be a treasure trove of data, and it will all be made available openly to the research community at the end of the study.
Our hope is that it will seed substantial new scholarship. 

Researchers can examine real-time behavioral cascades among infant behaviors, among mother behaviors, and between infants and mothers. 
They can test whether particular infant behaviors are temporally connected (e.g., vocalizations and gestures) or independent (vocalizations and locomotion). 
They can test infant-to-mother cascades and vice versa, such as whether infant emotional expressions affect real-time language input from mother. 
Prior correlational work, for example, shows that infants who express higher quantities of negative emotions display lower levels of language development on the MCDI and later language milestones [@Salley2007-gz; @Bloom1987-md]. 
But the evidence for these findings offers limited insight into the real-time behaviors that underlie the correlations81 [@Bloom1989-mw]. 
With PLAY, researchers can examine real-time behavioral cascades by testing whether infants’ negative emotions (Table 1 VE1) hinder interactions with objects (Table 1 VO1) and/or vocal and gestural communications (Table 1 VL2-3), and consequently, lead to low quantity and diversity of mother speech (Table 1 VL1-2). 
Infant emotions could also facilitate language learning: Emotional expressions might elicit mental state terms and emotion words from mothers (e.g., “You think mommy’s leaving?”, “Why are you sad?”). 
Regardless, whether and how infant emotions affect their language development requires data on the words mothers use preceding, during, and following infant emotional behaviors in real time.

PLAY’s three age groups and measures of skill and experience (e.g., MCDI, walking experience) allow researchers to investigate developmental cascades in new ways. 
We can examine age-related changes in temporal coordination among infant, mother, and infant-mother behaviors—such as whether infants of different ages with different skills elicit different behaviors in mothers. 
For example, object interactions in 12-month-olds, who are typically at the cusp of conventional word use, might elicit declaratives from mothers (“That’s a truck!”), whereas object interactions in 24-month-olds, who typically have substantial expressive vocabularies, might elicit interrogatives (“What’s that?”). 
Alternatively, researchers might compare language cascades in infants of different ages but with similar skills—whether the vocalizations of 18- versus 24-month-olds matched on MCDI vocabulary size elicit similar or different language input from mothers. 
Finally, we might compare real-time cascades in infants of the same age but with different skills—such as whether 18-month-olds who use isolated words versus those who combine words into simple sentences, elicit different language input from mothers. 
Comparisons of real-time contingencies by infant age and skill level provide a unique window into understanding developmental mechanisms that underpin behavioral change.

Environmental cascades. PLAY’s rich array of environmental measures, ranging from distal macro environmental characteristics (e.g., SES, geographic region) to proximal environmental features (e.g., clutter and chaos), will advance understanding of how environmental risks affect everyday opportunities for learning. 
Researchers might test proximal environmental cascades on the quantity and quality of infants’ object interactions and locomotion, for example by coding video home tours (Table 1 VH1) for object availability and
using laser measurements of room dimensions (Table 2 NH2). 
We can relate environmental features of clutter, ambient noise, and so on, to mothers’ speech and infants’ language development. 
Researchers can expand the lens of environmental influences to consider how distal macro factors, such as family SES and geo-coded data on neighborhood poverty (Table 2 NH5) relate to proximal environmental measures—objects and space in the home—and in turn infant behaviors, mother behaviors, and infant language and skill.

## Transparency and reproducibility

In addition to its scientific innovations, PLAY aims to serve as a model of how big data science can proceed in a maximally transparent and reproducible way.

### Data sharing
All video and self-report data will be openly shared with the research community on Databrary [@databrary-site], a digital web-based library for sharing and reusing research videos, clips, and displays that has received support from NSF, NICHD, SRCD, The Sloan Foundation, and the LEGO Foundation.
Videos associated with all procedures and code definitions will also be hosted and shared on Databrary and linked to the wiki.
The PLAY launch group will have a short period of exclusive access to the data before the full dataset is shared in the summer of 2023, at the end of the projected NICHD grant period.
By sharing all data, procedures, and coding information openly, other researchers can reuse shared videos to ask questions beyond the scope of the original study [@Adolph_undated-od]. 
They can use shared video clips to learn about procedures and to illustrate findings and displays for teaching [@Gilmore2017-eh]. 

Of course, video contains personally identifiable information, so sharing poses special ethical issues that Databrary's policy framework solves developed a policy framework53,54 for sharing identifiable data based on obtaining participants’ permission to share and restricting access to authorized researchers under the oversight of their institutions. 

### Free, open-source tools
PLAY is committed to using and deploying free and open source tools wherever possible.
Databrary itself is a free and open-source application [@databrary-on-github].
Datavyu [@datavyu-site; @Adolph2015-oy] is a powerful, flexible, coding tool that allows researchers to manipulate the temporal-spatial properties of behavior and to tag portions of the video for events and behaviors of interest. 
With fingertip control over video playback, they can run the video forward and backward at varying speeds (±1/32- 32x normal speed) or jog frame by frame to determine when behaviors began and ended, freeze frames to dissect behavior into its component parts, zoom in/out to focus on details or the larger context, and label behavioral events with categorical and qualitative codes. 
Each code is time-locked to the video to facilitate tests of behavioral cascades and real-time contingencies based on sequential order, duration, and begin/end times of events. 
A full scripting language allows researchers to manipulate the spreadsheet, error-check entries, import other data streams, and export data to their specifications for analyses. 
The latest Datavyu release has new features to reduce the notoriously high cost of transcribing infant and mother speech in noisy contexts, time locked to video, at the utterance level (from the typical 10-12 hours per hour of video to 7-9 hours).

### Open, transparent, and reproducible workflows
We have already begun to develop and deploy reproducible workflows using R.
A repository on Github (PLAY-behaviorome) has been created to house processing scripts for the PLAY data [@cite-PLAY-behaviorome] including analyses of the PLAY launch group members characteristics, characteristics of the data collection sites, and so on.
Indeed, the summary statistics about the PLAY Launch Group and the pilot study participants were derived directly from raw data files and incorporated into this manuscript using the `papaja` package [@R-papaja] we used to create the paper.
The PLAY-behaviorome repository includes the newly released alpha version of the `databraryapi` R package [@databraryapi] for interacting with Databrary from within R.
We welcome community input on the package, and we plan to improve the package over time.
We will eventually release a Python version, as well.
In addition, this paper's analyses and plots can be re-generated from the repository associated with the working manuscript [@ibad-PLAY-github].

### Reducing false-positives and pre-registration
Naturally, The creation of a large dataset with many variables raises the possibility that a particular statistically significant finding may be spurious. 
In particular, correlational analyses among non-video questionnaire data require special protection against spurious findings because of the large number of easily available measures (Table 2). 
The corpus includes a summary score for each infant on each instrument, subscores for standard scales, and raw data for each item. 
For example, researchers will have access to infants’ total productive vocabulary on the MCDI, the number of words produced within specific categories (e.g., animal words; action words), and production of each word.
Similarly, researchers will have access to fully processed, ready-to-analyze data on infant temperament, locomotor experience, infant health, environmental chaos, media use, family demographics, and so on.
Spurious results and duplication of analyses are especially likely from these “low-hanging fruit.”

In contrast to the ready-to-use questionnaire data, analyses of time-locked video codes raise other analytic issues. 
Data from the foundational coding passes will not be “ready to go.”
Researchers will need to make decisions about how to process the data—whether to turn categorical codes into frequencies or rates; whether to convert onset/offset times into average durations, latencies from one behavior to another, sequences of behavior, or other analytic constructs.
We will encourage individual launch group members to use their expertise and Datavyu training to mine the video corpus (by further coding of natural play and coding of structured play sessions and the home tour). Additional coding passes will be labor intensive, and duplication of coding effort would waste researchers’ time.

Of course, PLAY's homogenous sampling strategy and cross-sectional design have limitations. 
Although the sample will not be nationally representative, it will capture important demographic variations and can easily grow. 
With only one session per dyad, we cannot test stability or predictive validity of behaviors. 
However, the protocol and codes can be easily extended to other populations and to longitudinal designs (several launch group members plan to do this). If labs assigned to data collection or coding cannot fulfill their tasks, we will replace them.  
We will monitor ongoing data collections. 
If the data are too homogeneous, we will ask some sites to recruit more than their allotment. 
If a lab’s codes are not reliable, we will reassign the videos and retrain the coder.

## Conclusion

In conclusion, the PLAY project represents an innovative, synergistic, cross-domain approach to developmental science that will facilitate scientific discovery, transparency, and reproducibility we hope for years to come. 
In creating the first, large-scale, sharable, reusable, fully transcribed, coded, and curated video corpus of human behavior, we hope to establish video sharing of procedures, codes, and findings as a new standard in developmental and behavioral science.
In so doing, we hope to help answer fundamental cross-domain questions about behavioral, environmental, and developmental cascades as they shape the playful work of infants.

\newpage

# References
```{r create_r-references}
r_refs(file = "r-references.bib")
```

\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}
