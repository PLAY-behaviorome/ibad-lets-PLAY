---
title             : "Big data about small people: The Play & Learning Across a Year (PLAY) Project"
shorttitle        : "PLAY Project"

author: 
  - name          : "Rick O. Gilmore"
    affiliation   : "1,3"
    corresponding : yes    # Define only one corresponding author
    address       : "Department of Psychology, University Park, PA 16802"
    email         : "rogilmore@psu.edu"
  - name          : "Karen E. Adolph"
    affiliation   : "2,3"
  - name          : "Catherine L. Tamis-LeMonda"
    affiliation   : "2"
  - name          : "Kasey Soska"
    affiliation   : "3"
  - name          : "Joy L. Kennedy"
    affiliation   : "2,3"

affiliation:
  - id            : "1"
    institution   : "The Pennsylvania State University"
  - id            : "2"
    institution   : "New York University"
  - id            : "3"
    institution   : "Databrary.org"

author_note: |
  Rick O. Gilmore is in the Department of Psychology, The Pennsylvania State University, University Park, PA 16802.
  Karen E. Adolph is in the Department of Psychology, New York University, 4 Washington Place, New York, NY 10003.
  Catherine L. Tamis-LeMonda is in the Department of Applied Psychology, New York University.
  Kasey Soska is is Scientific Project Director at Databrary.
  Joy L. Kennedy is Scientific Support Specialist at Databrary.
  We acknowledge support from the National Science Foundation (BCS-1238595), the Eunice Kennedy Shriver National Institute for Child Health and Human Development (U01-HD-076595), the Society for Research in Child Development, the Alfred P. Sloan Foundation, and the LEGO Foundation.

abstract: |
  Piaget, Montessori, and Bruner observed that play is the work of infants.
  The PLAY (Play & Learning Across a Year) project seeks to catalyze discovery about the form and dynamics of this essential work across a critical period from 12 to 24 months of age when infants show remarkable advances in language, object interaction, locomotion, and emotion regulation.
  PLAY will leverage the joint expertise of 65 “launch group” researchers and capitalize on the Databrary video-sharing library and Datavyu video-coding tool to exploit the power of video to reveal the richness and complexity of behavior. 
  The PLAY researchers will collect, transcribe, code, share, and exploit a video corpus of infant and mother naturalistic activity in the home to test hypotheses about behavioral, developmental, and environmental cascades. 
  In turn, the project will demonstrate the value and feasibility of a cross-domain synergistic approach to infant research while advancing new ways to use video as data and documentation to facilitate discovery and ensure transparency.
  
keywords          : "keywords"
wordcount         : "X"

bibliography      : ["bib/r-references.bib", "bib/play.bib"]

figsintext        : no
figurelist        : no
tablelist         : no
footnotelist      : no
lineno            : yes

lang              : "english"
class             : "man"
output            : 
  papaja::apa6_pdf: default
  html_document:
    toc_float: true
    toc: true
  github_document:
    toc: true
---

```{r configure-document, include = FALSE}
knitr::opts_chunk$set(echo = FALSE, 
                      warning = FALSE, 
                      error = FALSE,
                      message = FALSE,
                      dpi = 300
                      )
```

```{r load_packages, include = FALSE}
library(papaja)
library(tidyverse)
library(httr)
library(stringr)
library(choroplethr)
library(choroplethrMaps)
library(tidyr)
library(databraryapi)
library(ggmap)

play.palette <- scale_fill_manual(values=c("blue2", "firebrick2", "chartreuse2", "darkorchid2"))

play.theme <-   
  theme_classic() +
  theme(legend.position = "bottom",
        legend.title = element_blank(),
        legend.text = element_text(size = rel(1.2)),
        axis.title = element_text(size = rel(1.5), face ="bold"),
        axis.text.x = element_text(size = rel(1.2)),
        axis.text.y = element_text(size = rel(1.2)),
        axis.line = element_blank(),
        axis.title.y = element_blank())
```

```{r get-install-census-key, include = FALSE}
# Get a Census API key from <https://api.census.gov/data/key_signup.html>
# install it via api.key.install(key)
```

```{r analysis_preferences, include = FALSE}
# Seed for random number generation
set.seed(42)

csv.dir <- "csv/"
r.dir <- "csv/"

source("R/numbers2words.R")
source("R/Cap_all.R")
source("R/Init_cap.R")
source("R/census.api.key.R")

login_db()
```

Behavior lies at the core of developmental science [@Gibson1994-kb].
It is a uniquely powerful tool for capturing the richness and complexity of behavior [@Adolph_undated-od; @Gilmore2017-eh], documenting its microstructure in real time and global patterns of change over development [@Gesell1991-sx; @Gesell1946-qr]. 
Video chronicles who did what, and how, when, and where they did it [@Gilmore2016-wl; @Gilmore_undated-tp; Adolph2017-ac].
Most infancy researchers collect video as primary data or as a backup to online coding procedures, but until recently, few have openly shared video because of ethical and technical challenges.
As those challenges recede and the culture of developmental science begins to embrace more open, transparent, and reproducible practices [@many-babies], the time is ripe to capitalize on the unique power of video to catalyze discovery and transform knowledge about behavioral development in infancy.

The Play & Learning Across a Year (PLAY) project [@Adolph_KE_Gilmore_RO_Tamis-LeMonda_CT_undated-bf; @Adolph2018-wc] builds on the NICHD/NSF-funded Databrary video-sharing library [@Gilmore2016-ev; @databrary-site] and the Datavyu  video-coding tool [@datavyu-site; @Adolph2015-oy]  developed and supported by Adolph and Gilmore, and it unites the joint expertise of 65 PLAY “launch group” researchers in the United States and Canada. 
PLAY will create the first-of-its-kind, large-scale, openly shared, readily reusable, transcribed, coded, and curated video corpus of human behavior. 
In addition, PLAY seeks to advance new video-based means of research documentation that hold promise to increase transparency and bolster reproducibility [@Adolph2017-ac, @Gilmore2017-eh] across the behavioral sciences.
<!-- The project has three aims: 1. To create the first cross-domain, large-scale, transcribed, coded, and curated video corpus of human behavior—collected with a common protocol and coded with common criteria; 2. To answer fundamental questions about behavioral and developmental cascades; and 3. To demonstrate the scientific value, feasibility, and scalability of a synergistic approach to collaborative research, and advance new ways to use video as documentation to ensure transparency and reproducibility. -->
In this paper, we describe the process of planning PLAY, our preliminary results from a small pilot study, and plans for a larger scale implementation we expect to launch in late 2018.

# Project Planning

```{r get-PLAY-roster}
play.pis <- read_csv("csv/play-pis.csv")
n.pis <- length(unique(paste0(play.pis$Last, play.pis$First)))
n.institutions <- length(unique(play.pis$Institution))
n.states <- length(unique(play.pis$State))
```

We named the project “PLAY” and use the terms “unstructured play” and “everyday play” to broadly refer to infants’ natural activities while awake. 
To paraphrase Piaget [@Piaget1967-nl], Montessori [@Montessori1984-la], and Bruner [@Bruner1975-sp; @Bruner1976-ab], play is the work of infants.
It is an approach to action, not a particular form of activity.
Some of infants’ play involves toys and some play is joyful and goal directed, but all of their spontaneous vocalizations, interactions with objects and people, and locomotor bouts involve exploration and opportunities for learning and growth, regardless of affect or intent.

Planning began in late 2015.
Adolph, Tamis-LeMonda and Gilmore (PLAY PIs) invited researchers to join the launch group based on their interest in open science and infant-mother natural activity in the home, willingness to collaborate on data collection and coding, lab location, and domains of expertise (language, gesture, play, object exploration, tool use, locomotion, posture, physical activity, emotion, temperament, parent responsiveness, gender, home environment, media use, spatial demography, and sampling). 
Nearly every invitee agreed.
The current launch group consists of `r n.pis` from `r n.institutions` institutions and `r n.states` states. `r round(with(play.pis, table(New)/sum(table(New)))*100, 0)[1]`% are new investigators, `r round(with(play.pis, table(Gender)/sum(table(Gender)))*100, 0)[1]`% women, `r round(with(play.pis, table(Race_eth)/sum(table(Race_eth)))*100, 0)[1]` non-white, from varied institutions (public and private universities and colleges, hospitals, agencies) with varied resources (`r sum(round(with(play.pis, table(Institution_Type)/sum(table(Institution_Type)))*100, 0)[1:3])` public universities, `r round(with(play.pis, table(R15_eligible)/sum(table(R15_eligible)))*100, 0)[1]`% R15-eligible institutions) across the United States and Canada.
Figure \@ref{fig:play-site-map}

```{r play-site-map, fig.cap = "A map of the PLAY project data collection sites."}
site_data <- read.csv(paste0(csv.dir, "city-state-county.csv"))

n.counties <- dim(site_data)[1]

# Datascience toolkit site source="dsk" more robust for multiple free queries
get_latlon <- function(i, sites) {
  county.state <- paste0(sites$County[i], " ", sites$State[i])
  latlon <- ggmap::geocode(county.state, output="latlon", 
                           source="dsk", messaging = FALSE)
  if (!is.null(latlon)) {
    return(latlon)
  } else {
    cat(paste0("Lat/Lon not returned for .", city.county.state))
    return(NULL)
  }
} 

if (n.counties > 0) {
  lat.lons <- lapply(1:n.counties, get_latlon, site_data)
  lat.lons.df <- Reduce(function (x,y) merge(x,y, all=TRUE), lat.lons)
}

site_latlons <- cbind(site_data, lat.lons.df)

myMAP <- get_map(location='united states', zoom=4, maptype='terrain', source='google', color='color')

ggmap(myMAP) +
  geom_point(data = site_latlons, 
             aes(x = site_latlons$lon, 
                 y = site_latlons$lat, color = "red")) +
  theme(legend.position = element_blank())
```


To distribute the burden of video coding across researchers, we recruited 10+ experts to shape the development of coding passes in four fundamental domains--communication, object interaction, locomotion, and emotion.
These domains represent key areas of infant development and provide foundational information for future discovery when time-locked to video.
Compared with other behaviors (e.g., visual attention), these are quick, easy, and reliable to code.
Experts in language and communication  transcribe all mother speech and infant vocalizations in formats exportable to CHILDES [@MacWhinney2000-yn]. 
These codes should be informative even to non-experts and are designed to facilitate further discovery through subsequent coding passes that build on the prior work. 
Temporally aligned transcriptions and codes should enable researchers with expertise in any domain to analyze cascades within and among these behaviors.

Through a yearlong series of telephone conversations with each launch group member and 12 group webinars [@PLAY-webinar-Databrary], we jointly developed a common sampling method and protocol (including materials, technical specifications, questionnaires, and non-video measures), designed common video codes, and established an infrastructure to divide responsibilities between PLAY staff and launch group.
We achieved consensus, with input from NICHD program staff, about all aspects of PLAY at a daylong workshop at NIH in December 2016, materials from which are shared on Databrary [@PLAY-workshop-Databrary].

The launch group jointly decided that the centerpiece of PLAY would be 900 one-hour videos of infant-mother dyads during natural play in the home. 
Home videos are widely believed to be representative of natural activity, and provide a stark contrast to the 2- to 20-minute "snapshots" typical of standard structured lab tasks.
Based on their extensive experience with naturalistic home observations [@Karasik2011-mf; @Karasik2014-cd; @De_Barbaro2015-bp; @Karasik2012-jq; @Karasik2015-mi; @Soderstrom2013-xn; @Rowe2012-vy; @Fausey2016-kx; @Iverson2007-yr], launch group members determined that one hour is sufficiently long to capture an ecologically valid window into infant and mother natural behaviors.
Longer recording times produce diminishing returns, risk infants becoming excessively tired or hungry, and increase the cost and burden to families and researchers.

Given the cost of going to families’ homes, the launch group also determined that we should augment recordings of natural play with a set of additional video, questionnaire, and non-video measures, that together would add only ~45 minutes to the home visit. 
This would enable researchers to test whether variations in natural play, or in characteristics of distal and proximal environments, predict infant and mother behaviors when materials and conditions are held constant. 
Thus, the solitary and dyadic play tasks are of interest in their own right, and might also serve as correlates in tests of experiential and environmental influences.

To obtain objective data on stable home conditions (cracks in walls, broken windows, ceiling stains, safety issues, etc.), physical layout (furniture, clutter, space to move, etc.), educational and electronic media (writing/drawing materials, TVs, computers, etc.), and gendered characteristics of infants’ room, toys, and clothes, we decided to conduct video home tours.
Launch group experts also expressed interest in understanding whether clothing and footgear affect infants’ locomotion and physical activity, and each takes only moments to video record.
Clothing/footgear videos can reveal gendered features (bows/frills, superhero emblems, patent leather shoes, army boots)66 and influences on spontaneous activity and locomotion [@Cole2012-vr].
The launch group also deemed important a variety of questionnaire measures of infant skills, experiences, and home environment: mothers’ report of infants’ vocabulary, locomotor milestones and falls, temperament, and use of gender labels; mother’s report of family demographics, media use, health, and home chaos; and a researcher-completed survey on physical characteristics of the home. 
The PIs developed a custom tablet-based app to collect these questionnaire data efficiently, limit data input errors, use a stylus for flexible data entry, and allow automatic transfer to permanent storage on Databrary.
The launch group devised methods to measure room size with a commercial laser device and ambient noise level with a commercial decibel meter.
Finally, with input from the launch group, we decided to transcribe all mother speech and infant vocalizations in the CHAT format exportable to CHILDES [@MacWhinney2000-yn]. 
These codes should be informative even to non-experts and are designed to facilitate further discovery through subsequent coding passes that build on the prior work. 
Temporally aligned transcriptions and codes should enable researchers with expertise in any domain to analyze cascades within and among these behaviors.

# Pilot Study

Based on the launch group's recommendations, we carried out a pilot study in the New York City area to test the feasibility of the approach.

## Methods

### Participants

```{r download-spreadsheet-from-db}
this.vol <- 444
vol.444 <- download_csv(this.vol)
```

```{r calculate-demo-data}
n.subs <- dim(vol.444)[1]

age.by.gender <- with(vol.444, table(participant.gender, group.name))
race.by.ethnicity <- with(vol.444, table(participant.race, participant.ethnicity))
n.white <- sum(race.by.ethnicity[4,])
n.asian <- sum(race.by.ethnicity[1,])
n.multi <- sum(race.by.ethnicity[2,])
n.unreported <- sum(race.by.ethnicity[3,])
n.hispanic <- sum(race.by.ethnicity[,1])

# Clean-up to save memory
rm(vol.444)
```

A total of $n=$ `r n.subs` infants were tested, $n=$ `r sum(age.by.gender[,1])` 12-month-olds (`r age.by.gender[1,1]` female), $n=$ `r sum(age.by.gender[,2])` 18-month-olds (`r age.by.gender[1,2]` female), and $n=$ `r sum(age.by.gender[,3])` (`r age.by.gender[1,3]` female) 24-month-olds. 

We chose these ages because 12- to 24-months represents a period of important, rapid growth when children begin talking, using objects in symbolic play, walking, and regulating emotions. 
For example, by 12 months, about half of infants can walk and half still crawl. 
By 18 months, infants are proficient walkers, and by 24 months, they can run, walk backwards, and walk up stairs [@Robinson2015-qe; @Onis2006-le]. 
Around 12 months, infants produce their first words. 
By 18 months, most display a vocabulary spurt, and by 24 months infants combine words into simple sentences [@Bloom1995-xb; @Hoff2013-er]. 
But these ages represent only group averages; individual infants show tremendous variability in these behaviors at each age.

All infants recruited were from the New York City area. 
`r Init_cap(numbers2words(n.white))` infants were White, `r numbers2words(n.asian)` was Asian, `r numbers2words(n.multi)` reported more than one race, and `r numbers2words(n.unreported)` did not report a race.
`r Init_cap(numbers2words(n.hispanic))` were of Hispanic or Latino ethnicity.

### Procedure

A publicly-accessible wiki [@Soska2016-yo] was used to document all procedures and code definitions.
The wiki links descriptions of every aspect of the protocol with exemplar third-person video clips (e.g., researcher scheduling home visit) to demonstrate typical procedures. 
The wiki links text-based descriptions of each code to video clips illustrating the types of behaviors that do and do not satisfy the coding criteria.
<!-- Many video-using researchers create codebooks and coding manuals, but this is the first time the authors have used video to augment these documents. -->
<!-- These ways of using video as documentation are simple, inexpensive to produce, have helped us increase transparency and reproducibility of critical components of the project. -->
<!-- The wiki aids staff training and ensures fidelity to the protocol and codes.  -->
<!-- The wiki documents the entire data collection protocol, all video-based measures including transcription and code definitions, and all questionnaire and non-video measures.  -->
<!-- It uses photos and video exemplars to make text-based descriptions clear and transparent.  -->
<!-- The wiki makes cross-site training consistent and cost-efficient and ensure that future researchers can reproduce our protocol with high fidelity. -->

### Data analysis

For this report, we used `r cite_r("r-references.bib")` for all of our statistical analyses.
Datavyu [@datavyu-site] was used for video coding.
All code used in data analysis and for this manuscript may be found in the GitHub repository associated with the paper [@ibad-PLAY-github].

To compute inter-observer reliability, we ran scripts in Datavyu to selects a random segment of video (25% or 5 mins) from each 20- minute segment of natural play. 
Inter-observer reliability for the pilot videos was 96.7%-99.3% exact frame agreement ($\kappa$s > .93, $ps$ < .001) for duration codes (object interactions, locomotion, emotion) and 94.1%- 99.5% code agreement ($\kappa$s > .89, $ps$ < .001) for categorical events (communicative acts, gesture).

## Results

Informal inspection of the videos verified that dyads were unaffected by the presence of the researcher: After a few minutes of acclimation prior to natural play, mothers and infants ignore the researcher.
<!-- Infants cry and breastfeed; mothers yell, talk on the phone, work on computers, go about daily chores, change infants’ diapers, and give infants snacks.  -->
<!-- The PIs verified the efficiency of the new custom tablet app for collecting questionnaire data. -->
Mothers appeared comfortable with all procedures, including the video home tour. 
The PIs found wide variation in home "disarray," suggesting parents present homes as they would for any other casual visitor.
<!-- **27 of 28 mothers agreed to share data**.  -->
Pilot testing verified the feasibility of collecting all data in < 2 hours.
So, with 1-2 hours of round-trip travel time, the entire data collection could be completed in < 4 hours.

All families were asked permission to share data with authorized researchers on Databrary using language adapted from the Databrary release template [@databrary-release].
Nineteen of the 20 families agreed to share; 3 families agreed to share data only with authorized Databrary researchers and 16 agreed to allow authorized researchers to show clips in public settings for informational or educational purposes.

In carrying out coding on X of the participants' sessions, we established that all four foundational coding passes are easy to learn (by undergraduate coders on Datavyu) and time efficient (< 3 hours for both infant and mother for each coding pass per hour of video).
Adaptations to Datavyu enable transcription in English or Spanish to take 7-9 hours per hour of video, while infant and mother communicative acts and gestures together take < 3 hours to code.

### Demographic and self-report measures

Due to some technical difficulties with pilot versions of the tablet app, we are only able to report here demographic and self-report data from $n=$18 families.
Reconstructions of the missing data from video are ongoing, and updates will appear on the project's Databrary volume [@play-pilot-volume] once those are completed.

```{r summarize-infant-birth}
cb <- read_csv("csv/child-birth.csv")
cb$birth_weight_g <- (cb$birth_weight_pounds + cb$birth_weight_ounces/16)*435.92
bw.sum <- round(fivenum(cb$birth_weight_g), 0)
```

Infants had largely uncomplicated, healthy births. 
Birth weights (in g) ranged from `r bw.sum[1]` to `r bw.sum[5]` (mean = `r mean(bw.sum)` g); `r length(with(cb, table(newborn_complications)))` had birth complications (e.g., C-section, preeclampsia).
Figure \@ref{fig:plot-sound-avg-db} shows the parent-reported ages for the onset of hands and knees crawling and walking using procedures Adolph has used previously.

```{r locomotion-plot, fig.cap = "Parent-reported onset ages for hands and knees crawling and walking"}
locomotion <- read.csv(paste0(csv.dir, "locomotion.csv"))

locomotion %>%
  gather(key = milestone, value = age.mos, hkcrawl_onset_mos, walk_onset_mos) %>%
  mutate(milestone = factor(milestone, labels = c("crawl", "walk"))) %>%
  # arrange(desc(age.mos)) %>%
  ggplot() +
  aes(x = age.mos, y = id) +
  geom_point(aes(shape = milestone, color = milestone)) +
  geom_line(aes(group = id)) +
  xlab("Age (months)") +
  geom_rug(aes(x = age.mos, group = milestone, color = milestone),
           sides = "b") +
  play.theme
```

```{r clean-up-cb}
# Clean-up to save memory
rm(cb)
```

```{r summarize-family}
fam <- read_csv("csv/family.csv")
mom.ed.yrs <- with(fam, table(mom_education))
partner.ed.yrs <- with(fam, table(partner_education))
cohab.w.partner <- with(fam, table(partner_cohabitate))
mom.working <- with(fam, table(mom_working))
partner.working <- with(fam, table(partner_working))
```
Mothers reported having between `r min(fam$mom_education, na.rm = TRUE)` and `r max(fam$mom_education, na.rm = TRUE)` years of education, ($M=$ `r round(mean(fam$mom_education, na.rm = TRUE),1)`) and `r sum(mom.working[c('ft', 'pt')])` were working at least part time.
Sixteen of the eighteen repondents reported a partner cohabitating with the family.
The partner's education level ranged from `r min(fam$partner_education, na.rm = TRUE)` and `r max(fam$partner_education, na.rm = TRUE)` years of education, ($M=$ `r round(mean(fam$partner_education, na.rm = TRUE), 1)`) and `r sum(partner.working['ft'])` were working at least part time.

```{r summarize-language-exposure}
lang.exp <- read.csv("csv/language-exposure.csv")
span.to.child <- with(lang.exp, table(language, exposure_context))['Spanish', 'to_child']
span.in.childcare <- with(lang.exp, table(language, exposure_context))['Spanish', 'childcare']
non.english <- with(lang.exp, (table(id, language)))[,c('Armenian', 'Other', 'French', 'Hindi', 'Spanish', 'Polish', 'Russian')]
# Clean-up to save memory
#rm(lang.exp)
```
All of the infants were exposed to and spoken to in English in the home.
Many were spoken to or had exposure to languages other than English.
At home `r span.to.child` infants were spoken to in Spanish; `r span.in.childcare` infants were exposed to Spanish in a childcare setting.
Other children were exposed to Armenian, French, Hindi, Polish, and Russian in the childcare setting.
Six children in this sample were exposed only to English.

### Ambient sound levels

Figure \@ref{fig:plot-sound-avg-db} shows the average ambient sound levels recorded from the sites during an hour of recording, and Figure \@ref{fig:plot-sound-peak-db} shows the peak ambient sound levels.

### Video coding

## Discussion

The pilot study verified that the protocol met the launch group's criteria on scientific and practical grounds.
Four of the full sessions (13, 18, 29, and 20) met all internal criteria benchmarks.
So we proceeded to design and plan a full-scale implementation.

# Planned study

The proposed study builds upon and extends the pilot study.

## Methods
A publicly-accessible wiki similar to the one used in the pilot [@Soska2016-yo] will be used to document all procedures and code definitions.

### Participants

```{r update-collecting-counties}
play.pis %>%
  filter(Collection_role == "Collecting") ->
  collecting.pis

n.states.collecting <- length(unique(collecting.pis$State))
```

We will collect data from $n=900$ infant-mother dyads from at least 30 different communities in `r n.states.collecting` states located around the U.S.
Each site will collect data from 30 infants, 10 each at 12-, 18-, and 24-months of age (+/- 1 week), with equal numbers of females and males. Figure \@ref(fig:PLAY-sitemap) shows the proposed data collection sites and the non-collecting, data coding and analysis sites.

While not designed to be nationally representative, the data collection sites are diverse in aggregate based on Census data.
To gather Census data reproducibly, we used the `choroplethr` package [@R-choroplethr; @R-choroplethrMaps] to download data from the Census Bureau's public API.
This workflow allows us to easily gather and analyze other Census Bureau data about the communities targeted for sampling.

[](figs/race-by-county-all-regions-plot-1.pdf)

[](figs/per-capita-income-plot-1.pdf)

[](figs/ed-attain-bars-plot-1.pdf)

[](figs/spanish-speaking-plot-1.pdf)

Figure \@ref(fig:PLAY_race) shows the proportion of African American, Hispanic/Latino, and Asian residents in the counties surrounding the collection sites from which participating researchers will recruit.
Figures \@ref(fig:PLAY-econ-plot) and \@ref(fig:PLAY-ed-plot) show economic and educational attainment indicators, respectively.
Figure \@ref(fig:spanish) shows the proportion of households speaking only English versus those where Spanish or other languages are spoken, exclusively or in addition to English.
Data collection sites will have soft, advisory recruiting targets based on these sorts of measures for their individual communities.

Families will be two-parent, English and/or Spanish speaking households with resident fathers, with both parents greater than 18 years of age.
Infants will be term firstborns, without birth complications or disabilities, and 12, 18, or 24 months of age (±1 week); half of infants at each age and site will be boys. 

The launch group deliberated over several sampling strategies [@Bornstein2013-mr; @#Jager2017-wv; @{DavisKean2017-sr]
Ultimately, we decided on homogeneous sampling to contain costs and understand behavioral variation. 
Homogenous sampling maintains some control over sample characteristics through a set of inclusionary criteria (here, firstborn status, English/Spanish home language, term pregnancy, etc.), while maximizing select aspects of diversity (e.g., geography, SES) and retaining sufficient power for group comparisons. 
We ruled against conventional convenience sampling, which leaves sampling decisions entirely to researchers’ discretion. 
Although convenience sampling is easy and cost efficient, it risks yielding a sample that varies on too many demographic dimensions to control. 
At the other extreme, population-based (probability) sampling is cost-prohibitive due to the required sample size. 
The sheer volume of data would prohibit transcription and video coding, and would require hiring and training special researchers for data collection, rather than relying on the existing expertise of the launch group.

### Procedure

During an initial screening call, a researcher will determine eligibility for participation, and obtain demographic information. 
The researcher will schedule a 2-hour visit (weekday or weekend) when infants are between naps, meals, and baths, and would normally be home with their mothers. 
At the end of the visit, the researcher will ask mothers if the one-hour natural play session was representative of a typical day at home. 
If mothers report that infants’ behavior or health was atypical, we will replace the dyad and document the replacement.

The visit will include, in order, parent consent, one-hour natural play, two structured play tasks, questionnaires, video home tour, and Databrary sharing permission. 
Although mothers will agree to share data in the initial screening call, we will request their signed permission at the end of the home visit when they are maximally informed. 
Consent, sharing permission, and questionnaire data will be entered on the custom app; paper forms and video camera on tripod will provide backup. Based on the pilot study, and our own experience in other studies, we anticipate that most families agree to share data. 
If families decline to share, their data can still be stored on Databrary and used by the collecting researcher for their own purposes. 

Natural play: Like the pilot, we will record one hour of infant and mother activity in the home. 
Infant and mother will go about their daily routines without restrictions. 
They can move from room to room; mother can do chores; TV, music, or other media can be on.
All of these behaviors were common in our pilot data. 
The researcher will hand-hold an HD video camera at the child’s eye level, prioritizing view of infant over mother, keeping the infant’s face, hands, and feet in view. 
If mother is visible, the researcher will capture as much of her face and body as possible without losing view of the baby. 
A cardioid microphone will amplify infant and mother speech and isolate background noise.
Home visits avoid the artificiality of unfamiliar lab environments, materials, and tasks, and therefore come closest in fidelity to infant and mother natural behavior. 

We will take several precautions to minimize effects of experimenter and camera presence on dyads [@McCune-Nicolich1984-tn; @Stevenson1986-zh]. 
We will train researchers to remain unobtrusive. 
They will stay at a distance, resist talking to mother or infant, and watch the infant through the viewfinder to avoid eye contact. 
Filming will begin after several minutes of infant-mother acclimation to the camera and researcher.

Solitary play will entail infants playing with a set of 10 nesting cups (placed half up, half down) while sitting on a mat with mother nearby but not interacting (2 minutes). 
Nesting cups can reveal developmental differences in attention, manual action, spatial problem solving, and symbolic play. 
Younger pilot infants manually explored the cups but had difficulty nesting consecutive sizes; older pilots nested cups and used them symbolically (e.g., pretended to drink). 
In dyadic play infant and mother will play together on the mat with a standard set of toys (3 minutes)— truck, doll, baby bottle, small blanket, 2 tea cups, plates, and spoons—with mother instructed to “share the toys with her child.” 
The toys are conducive to non-symbolic (stacking plates, cups), symbolic (feeding doll, putting doll to sleep), and gendered play (with truck versus doll).

Following the play episodes, the researcher will walk through each room, filming walls, floors, ceilings, windows, room contents (including infants’ toys, books, media), and the contents of infants’ closets and drawers. 
The mother will name each room, describe infant’s access to rooms and spaces, and open closet doors and drawers for filming. 
Prior work and piloting ensured that mothers did not find this procedure intrusive. 
The researcher will narrate the video with comments about floor coverings (“throw rug,” “linoleum”) and anything not transparent to video.

During the visit, the researcher will record the clothes (front and back) and footgear (bottom, side, top) infants wore during the natural play session, and record the date infants began wearing the shoes and for how many days/week infants play indoors in shoes, socks, and barefoot.

After the naturalistic and structured play tasks, the researcher will interview mothers on a range of infant and family measures that will yield information about language, locomotion, temperament, gender, home environment, and health (Table 2). The researcher will administer all questionnaires orally, and video records the interview (camera on tripod) for quality assurance, transparency, and possibly later coding.

Language (QL1): We will use the 12-month (words and gestures) and 18- to 24-month (words and sentences) versions of the MacArthur-Bates Communicative Development Inventory (MCDI). The MCDI is the most widely used instrument of infant language development, administered to over 60,000 children in 23 languages75. The 12-month MCDI measures receptive and expressive vocabulary size and communicative gestures; the 18- to 24-month version contains a larger set of vocabulary items and simple sentence constructions. NL2: Mothers will report the language(s) spoken to infant by parents and childcare workers.
Locomotion (QM1): Mothers will report the onset ages of hands-knees crawling and walking, using cell phone videos, photos, and diaries to jog their memories76,77. QM2: Mothers will report on infants’ fall-related injuries.
Infant temperament (QE1) will be indexed with the Rothbart Early Childhood Behavior Questionnaire (ECBQ), very short form78,79, which measures dimensions of surgency, negative affect, and effortful control.
Gender (QG1): Mothers will report infants’ use of gender labels (e.g., boy, girl) to refer to themselves or other people. QG2: Mothers will report their own and the father’s attitudes to gender normative behavior (e.g., “I would be upset if my son wanted to dress like a girl”); and household division of labor (e.g., who does cooking).
Environment (NH1): Ambient noise will be measured during natural play with a decibel meter, placed in the main room, to record peak and average dB every 100 ms. NH2: In the home video tour, the researcher will measure room dimensions with a laser distance measurer. QH3: At the end of the visit, the researcher will fill out a survey on the home environment (from launch group member Evans). QH4: Mothers will report use of electronic media (TV, computers, apps, etc.) by infant and family members (from launch group member Barr).
Health (QF1-4): Mothers will report infant, parent, and family demographics, infants’ health history (based on a subset of questions from the ECLS-B 9-month and 2-year interviews), childcare experience, and parents’ and family health history including SLI, ASD, and mental illnesses.

### Video coding

Transcriptions and four core coding passes will be scored for both infant and mother.
PLAY staff will transcribe speech at the utterance level, using standard criteria for segmenting speech [@MacWhinney2000-fb]. 
Utterances will be defined by independent clauses (statements with subject and predicate) with modifiers. Intonation and pauses can also define breaks (e.g., “You like that . Right?” is two utterances). 
Mothers’ language-like sounds are typed out phonetically. 
Infant babbles are marked with “b” and non-linguistic vocalizations (cry, laugh, grunt) with “c.” 
Unintelligible utterances are marked “xxx.” Utterances will be time-locked to video, revealing overlaps in infant-mother speech, and co-occurrence and sequencing of speech with object interactions, emotions, and locomotion. Spanish transcriptions will follow the same rules.

Based on transcripts, mothers' utterances will be coded as declaratives (labels and descriptions of objects and events “Red”; “Puppy”), attention-imperatives that solicit infant attention (“Look at that”), action-imperatives that solicit infant action (“Put it there”), or prohibition-imperatives (“Stop it!”); interrogatives (open- and close-ended questions, “Is it hot?” with the exception of “tag” questions, which will be coded as declaratives, “That’s a ball, right?”); affirmation/conversational fillers (“Yes!”; “What’s next?”), and unintelligible. Infants’ vocalizations will be categorized as language (sentences or words), prelinguistic vocalizations (babbling or vowels), non-linguistic vocalizations (e.g., cry, laugh, scream, grunt), or unintelligible.

Gestures will be categorized as points, show/hold up (deictic), conventional (wave bye-bye, thumbs-up), and representational (flapping arms to represent a bird).

Object interactions will be coded for onset and offset of manual engagement (touching, manipulating, carrying) with any manipulable, moveable object or part of an object that moves through space.
Locomotion will be coded for onset and offset of self-generated locomotion of any form (e.g., crawling, walking, climbing, stepping in place). Coders also score falls, and periods when the infant is held or constrained by furniture (e.g., highchair).
Emotion will be coded for onset and offset of positive (smiling, laughing) and negative (crying, frowning, fussing) facial expressions.
Inter-observer reliability: 

To verify inter-observer reliability, PLAY staff will rescore 25% of each infant’s natural play video (5 minutes randomly drawn from each 20-minute segment), blind to the original coders’ output (categorical measures: kappas >.85; duration measures: % exact frame agreement > 90%). If codes are not reliable, PLAY staff will reassign the videos to a new lab.

### Data analysis

The launch group will jointly establish best practices for PLAY analyses.
Our guidelines will include: recommendations to pre-register predictions and analyses; the use of procedures that use one portion of the data set to explore correlations among variables and a separate subsample to confirm it; the use of reproducible and transparent workflows for data processing and analyses (e.g., Ruby scripts in Datavyu; syntax instead of menu-driven commands for SPSS users; scripts and functions for R users); a commitment to openly sharing supplementary video codes and operational definitions to avoid unnecessary duplication of coding efforts; and open sharing of null results as well as positive findings. 
We will create means for communication (e.g., a Google group) among launch group members who wish to discuss, propose, and organize team efforts focused on answering specific video-based research questions.
In addition, in keeping with emerging standards in research transparency, we will report how we determined our sample size, all data exclusions (if any), all manipulations, and all measures in the study. <!-- 21-word solution (Simmons, Nelson & Simonsohn, 2012; retrieved from http://ssrn.com/abstract=2160588) -->

# General Discussion

The PLAY corpus will be a treasure trove of data, and it will all be made available openly to the research community at the end of the study.
Our hope is that it will seed substantial new scholarship. 

Researchers can examine real-time behavioral cascades among infant behaviors, among mother behaviors, and between infants and mothers. 
They can test whether particular infant behaviors are temporally connected (e.g., vocalizations and gestures) or independent (vocalizations and locomotion). 
They can test infant-to-mother cascades and vice versa, such as whether infant emotional expressions affect real-time language input from mother. 
Prior correlational work, for example, shows that infants who express higher quantities of negative emotions display lower levels of language development on the MCDI and later language milestones [@Salley2007-gz; @Bloom1987-md]. 
But the evidence for these findings offers limited insight into the real-time behaviors that underlie the correlations81 [@Bloom1989-mw]. 
With PLAY, researchers can examine real-time behavioral cascades by testing whether infants’ negative emotions (Table 1 VE1) hinder interactions with objects (Table 1 VO1) and/or vocal and gestural communications (Table 1 VL2-3), and consequently, lead to low quantity and diversity of mother speech (Table 1 VL1-2). 
Infant emotions could also facilitate language learning: Emotional expressions might elicit mental state terms and emotion words from mothers (e.g., “You think mommy’s leaving?”, “Why are you sad?”). 
Regardless, whether and how infant emotions affect their language development requires data on the words mothers use preceding, during, and following infant emotional behaviors in real time.

PLAY’s three age groups and measures of skill and experience (e.g., MCDI, walking experience) allow researchers to investigate developmental cascades in new ways. 
We can examine age-related changes in temporal coordination among infant, mother, and infant-mother behaviors—such as whether infants of different ages with different skills elicit different behaviors in mothers. 
For example, object interactions in 12-month-olds, who are typically at the cusp of conventional word use, might elicit declaratives from mothers (“That’s a truck!”), whereas object interactions in 24-month-olds, who typically have substantial expressive vocabularies, might elicit interrogatives (“What’s that?”). 
Alternatively, researchers might compare language cascades in infants of different ages but with similar skills—whether the vocalizations of 18- versus 24-month-olds matched on MCDI vocabulary size elicit similar or different language input from mothers. 
Finally, we might compare real-time cascades in infants of the same age but with different skills—such as whether 18-month-olds who use isolated words versus those who combine words into simple sentences, elicit different language input from mothers. 
Comparisons of real-time contingencies by infant age and skill level provide a unique window into understanding developmental mechanisms that underpin behavioral change.

Environmental cascades. PLAY’s rich array of environmental measures, ranging from distal macro environmental characteristics (e.g., SES, geographic region) to proximal environmental features (e.g., clutter and chaos), will advance understanding of how environmental risks affect everyday opportunities for learning. 
Researchers might test proximal environmental cascades on the quantity and quality of infants’ object interactions and locomotion, for example by coding video home tours (Table 1 VH1) for object availability and
using laser measurements of room dimensions (Table 2 NH2). 
We can relate environmental features of clutter, ambient noise, and so on, to mothers’ speech and infants’ language development. 
Researchers can expand the lens of environmental influences to consider how distal macro factors, such as family SES and geo-coded data on neighborhood poverty (Table 2 NH5) relate to proximal environmental measures—objects and space in the home—and in turn infant behaviors, mother behaviors, and infant language and skill.

Databrary [@databrary-site], funded by NICHD/NSF, is a digital web-based library for sharing and reusing research videos, clips, and displays. 
Researchers can reuse shared videos to ask questions beyond the scope of the original study [@Adolph_undated-od]. 
They can use shared video clips to learn about procedures and to illustrate findings and displays for teaching [@Gilmore2017-eh]. 
Sharing is easy. 
To mitigate the onerous task of curating a dataset after the study is completed, Databrary developed an active curation system. 
Researchers can use Databrary as a file manager, lab server, and secure backup prior to sharing [@Gordon2015-jp; @databrary-site]. 
When they are ready to share, they need only click a button. 

Video contains personally identifiable information, so sharing poses special ethical issues. 
Advised by ethics experts, IRB and grants/contracts administrators, and legal counsel, Databrary developed a policy framework53,54 for sharing identifiable data based on obtaining participants’ permission to share and restricting access to authorized researchers under the oversight of their institutions. 
Since the Databrary website went live in 2014, 580+ researchers (including the launch group) and 245+ affiliates from 330+ institutions around the world are authorized. The repository contains 7820+ hours of video from 7830+ participants.
Datavyu [@datavyu-site; @Adolph2015-oy] is a powerful, flexible, coding tool that allows researchers to manipulate the temporal-spatial properties of behavior and to tag portions of the video for events and behaviors of interest. 
With fingertip control over video playback, they can run the video forward and backward at varying speeds (±1/32- 32x normal speed) or jog frame by frame to determine when behaviors began and ended, freeze frames to dissect behavior into its component parts, zoom in/out to focus on details or the larger context, and label behavioral events with categorical and qualitative codes. 
Each code is time-locked to the video to facilitate tests of behavioral cascades and real-time contingencies based on sequential order, duration, and begin/end times of events. 
A full scripting language allows researchers to manipulate the spreadsheet, error-check entries, import other data streams, and export data to their specifications for analyses. 
The latest Datavyu release has new features to reduce the notoriously high cost of transcribing infant and mother speech in noisy contexts, time locked to video, at the utterance level (from the typical 10-12 hours per hour of video to 7-9 hours).

Naturally, The creation of a large dataset with many variables raises the possibility that a particular statistically significant finding may be spurious. 
In particular, correlational analyses among non-video questionnaire data require special protection against spurious findings because of the large number of easily available measures (Table 2). 
The corpus includes a summary score for each infant on each instrument, subscores for standard scales, and raw data for each item. 
For example, researchers will have access to infants’ total productive vocabulary on the MCDI, the number of words produced within specific categories (e.g., animal words; action words), and production of each word.
Similarly, researchers will have access to fully processed, ready-to-analyze data on infant temperament, locomotor experience, infant health, environmental chaos, media use, family demographics, and so on.
Spurious results and duplication of analyses are especially likely from these “low-hanging fruit.”

In contrast to the ready-to-use questionnaire data, analyses of time-locked video codes raise other analytic issues. 
Data from the foundational coding passes will not be “ready to go.”
Researchers will need to make decisions about how to process the data—whether to turn categorical codes into frequencies or rates; whether to convert onset/offset times into average durations, latencies from one behavior to another, sequences of behavior, or other analytic constructs.
We will encourage individual launch group members to use their expertise and Datavyu training to mine the video corpus (by further coding of natural play and coding of structured play sessions and the home tour). Additional coding passes will be labor intensive, and duplication of coding effort would waste researchers’ time.

Of course, PLAY's homogenous sampling strategy and cross-sectional design have limitations. 
Although the sample will not be nationally representative, it will capture important demographic variations and can easily grow. 
With only one session per dyad, we cannot test stability or predictive validity of behaviors. 
However, the protocol and codes can be easily extended to other populations and to longitudinal designs (several launch group members plan to do this). If labs assigned to data collection or coding cannot fulfill their tasks, we will replace them.  
We will monitor ongoing data collections. 
If the data are too homogeneous, we will ask some sites to recruit more than their allotment. 
If a lab’s codes are not reliable, we will reassign the videos and retrain the coder.

In conclusion, the PLAY project represents an innovative, synergistic, cross-domain approach to developmental science that will facilitate scientific discovery, transparency, and reproducibility we hope for years to come. 
In creating the first, large-scale, sharable, reusable, fully transcribed, coded, and curated video corpus of human behavior, we hope to establish video sharing of procedures, codes, and findings as a new standard in developmental and behavioral science.
In so doing, we hope to help answer fundamental cross-domain questions about behavioral, environmental, and developmental cascades as they shape the playful work of infants.

\newpage

# References
```{r create_r-references}
r_refs(file = "r-references.bib")
```

\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}
